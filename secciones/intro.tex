\section{Introducción}
\label{cap-intro}

La estimación de distancias es fundamental para el funcionamiento seguro y eficiente de sistemas móviles y autónomos, como vehículos autónomos, robots móviles y asistentes personales, y se realiza tradicionalmente mediante sistemas de imágenes estéreo, multicámara o mediciones LiDAR. Sin embargo, estos enfoques presentan limitaciones en términos de costo, casos de uso, sincronización, complejidad de equipamiento y consumo energético \cite{agand2024dmode}. En contraste, la visión monocular, potenciada por avances en aprendizaje profundo, ha emergido como una alternativa viable y más accesible, permitiendo la estimación de profundidad a partir de una única imagen RGB\cite{zhao2020monocular}.\\
En este contexto, el proyecto desarrolla y valida un sistema de estimación de distancias a partir de video monocular filmado desde la perspectiva de un peatón, integrando un enfoque geométrico que aprovecha la altura real de los sujetos y los parámetros intrínsecos de la cámara, a partir de los cuales se construyó un conjunto de datos propio; el análisis estadístico de esas mediciones mostró que características visuales como la altura en píxeles y la coordenada vertical del centro del cuadro envolvente de cada persona correlacionan de manera consistente con la distancia real, lo cual orientó la selección de entradas del modelo. Sobre esa base se diseñó y entrenó una arquitectura recurrente para realizar regresión de distancia en secuencias temporales, y se integró un detector YOLOv8, sin reentrenamiento, para localizar peatones en cada cuadro y alimentar el sistema. Los resultados experimentales, muestran la capacidad del enfoque para generalizar a personas de alturas variables en escenarios dinámicos y establecen las métricas de error y limitaciones que guían futuras mejoras.   

\subsection{Antecedentes}

La estimación de distancias hacia objetos presentes en una escena posee la particularidad de que el objeto de interés puede seleccionarse según la finalidad de la aplicación. Por ejemplo, en \cite{GuzmanSee2023} se aborda un escenario de conducción en el que las placas vehiculares son el objeto principal, dado que mantienen dimensiones físicas estandarizadas a nivel nacional. Esta característica permite calcular la distancia mediante el modelo óptico del lente y, con apoyo de un mapa de profundidad generado por MiDaS \cite{ranftl2020towards}, extrapolar distancias hacia otros objetos de la escena.

En situaciones donde los objetos presentan variaciones naturales de tamaño, es posible recurrir a medidas promedio o estandarizadas. Tal es el caso de \cite{haseeb2018disnet}, donde para cada clase de objeto se establecieron alturas y anchos promedio que, junto con cuatro características extraídas del cuadro envolvente generado por YOLO, sirvieron como entrada para una red neuronal densa con capas de 100 neuronas cada una.

Si bien los perceptrones multicapa constituyen arquitecturas simples capaces de capturar patrones relevantes y mostrar resultados satisfactorios, presentan limitaciones en entornos dinámicos donde intervienen personas en movimiento. En estos escenarios, ignoran un factor esencial que la visión humana emplea para inferir profundidad: el movimiento. Para abordar esta limitación, \cite{Wang_2019_CVPR} propone un modelo que procesa secuencias de imágenes mediante una etapa inicial convolucional seguida de capas recurrentes, integrando así información temporal relevante para la estimación de distancias.

\subsection{Planteamiento del problema}

Considerando los antecedentes mencionados previamente, se vuelve necesario precisar con claridad cuál es el desafío específico que este proyecto busca atender. En la siguientes subsecciones se presenta la definición del problema, donde se delimitan los alcances técnicos, las restricciones operativas y las condiciones bajo las cuales se pretende desarrollar una solución y por qué se considera viable.

\subsubsection{Definición del problema}

Los estudios comparativos recientes sobre modelos de estimación monocular de distancias \cite{spencer2024third} muestran una clara tendencia hacia arquitecturas generativas de gran escala, destacando a DepthAnything como el modelo basado en transformers más influyente del 2024. Este tipo de soluciones ofrece resultados altamente competitivos y, en algunos casos, admite el procesamiento de secuencias de imágenes. No obstante, su implementación requiere recursos computacionales elevados, lo cual dificulta su adopción en sistemas de bajo costo, aplicaciones móviles o contextos que demandan tiempos de respuesta reducidos.

En contraste, cuando el interés se concentra en uno o pocos objetos específicos, y estos poseen dimensiones constantes, es posible recurrir a un cálculo directo de distancia mediante las características ópticas de la cámara. Sin embargo, este enfoque obliga a utilizar siempre el mismo dispositivo de captura, limitando la escalabilidad y restringiendo el uso a un conjunto reducido de usuarios. Por otro lado, cuando los objetos presentan variabilidad de tamaño, se podría optar por emplear medidas promedio para guiar a un modelo de predicción. No obstante, cuando la variabilidad es grande, como en el caso de las personas, esta estrategia introduce incertidumbre y puede comprometer la capacidad del modelo para generalizar.

Adicionalmente, gran parte de los avances en estimación de profundidad y detección de objetos se ha desarrollado en contextos vehiculares utilizando conjuntos de datos como KITTI, Cityscapes y nuScenes, diseñados desde la perspectiva de un automóvil en movimiento y orientados a la conducción autónoma \cite{niu2021monocular}. Esto limita la aplicabilidad de los modelos a entornos peatonales o interiores, donde las dinámicas de movimiento, las distancias relevantes y la interacción con el entorno difieren. Incluso en datasets más diversos, como DIODE, suelen privilegiarse configuraciones estáticas \cite{li2024synthetic}, dejando de lado escenarios con movimiento humano natural.

Finalmente, construir un conjunto de datos propio con valores de distancia reales precisos implica recurrir a sensores especializados, como LiDAR o sistemas láser de alta precisión, cuyo costo dificulta su uso en proyectos de bajo presupuesto. Esta barrera tecnológica subraya la necesidad de explorar alternativas que permitan generar estimaciones métricas utilizando únicamente cámaras monoculares y modelos de geometría óptica capaces de lograr resultados reales y con recursos limitados.

\subsubsection{Justificación}

La necesidad de estimar distancias de manera confiable en entornos peatonales es cada vez más relevante en aplicaciones como asistencia para movilidad, sistemas de vigilancia inteligente, robots de servicio y plataformas portátiles de bajo costo. Sin embargo, la mayoría de los avances recientes en estimación de profundidad se han centrado en contextos vehiculares y modelos de gran escala que requieren capacidades computacionales sustanciales, lo que limita su uso y accesibilidad para escenarios específicos con recursos limitados.

Ante este panorama, resulta pertinente explorar alternativas que aprovechen únicamente visión monocular, ya que una cámara RGB convencional representa un sensor económico, ampliamente disponible y de bajo consumo y mantenimiento. Asimismo, el uso de modelos geométricos para generar referencias de distancia evita depender de sensores costosos como LiDAR, volviendo viable la realización de un conjunto de datos propio y adaptado al dominio peatonal.

La integración de información temporal mediante redes recurrentes ofrece además la posibilidad de capturar señales dinámicas, como cambios en tamaño aparente o desplazamiento vertical del objeto detectado, que la visión humana utiliza de manera natural para inferir profundidad. Este enfoque permite desarrollar un sistema más cercano al comportamiento perceptual humano y mejor adaptado a situaciones reales donde los sujetos están en movimiento.

\subsection{Hipótesis}

Si se integra un modelo basado en parámetros intrínsecos de la cámara con un dominio representativo de alturas humanas para generar datos de entrenamiento, y se utiliza una red neuronal recurrente capaz de procesar secuencias visuales, entonces es posible estimar de manera precisa y generalizable la distancia a transeúntes en entornos dinámicos utilizando únicamente visión monocular, incluso cuando existe variabilidad en la estatura de las personas.

\subsection{Objetivos}

\textbf{Objetivo general}\\
Evaluar la eficacia de un sistema de estimación de distancias en entornos dinámicos, basado en visión computacional monocular y redes neuronales con capas recurrentes, desarrollado a partir de la integración de enfoques de modelado óptico, detección de objetos y análisis secuencial de información visual, con el fin de determinar su precisión y aplicabilidad en contextos peatonales.\\

\textbf{Objetivos específicos}
\begin{itemize}
    \item Generar un conjunto de datos propio con información de distancia calculada por métodos de óptica del lente, compuesto por secuencias de video capturadas desde la perspectiva de un peatón, como base para el entrenamiento, validación y análisis del sistema propuesto.
    \item Integrar y ajustar componentes de detección, seguimiento y estimación de distancia dentro de un marco de visión monocular, considerando la influencia del movimiento de los objetos presentes en la escena.
    \item Analizar el rendimiento del sistema desarrollado mediante métricas cuantitativas (\textit{MAE}, \textit{RMSE}, \textit{R\(^2\)} y \textit{MAPE} ) y la comparación de resultados frente a valores de referencia obtenidos experimentalmente.
\end{itemize}


\subsection{Aportación científica y/o tecnológica}

El presente trabajo plantea como aportación principal el desarrollo y validación de un modelo de percepción visual basado en visión computacional monocular, orientado a la estimación métrica absoluta de distancias a transeúntes en entornos dinámicos. A diferencia de enfoques genéricos y demandantes de recursos entrenados en dominios externos o con sensores especializados, el sistema propuesto se construyó a partir de la captura y anotación de un dataset propio, grabado con las características reales del sistema objetivo, lo que permitió ajustar el modelo a las condiciones particulares de observación y movimiento.

La Figura \ref{fig:blockDia} muestra el eje metodológico del proyecto que integra una etapa de estimación inicial basada en parámetros intrínsecos de la cámara y características físicas observables de los sujetos, seguida por un entrenamiento supervisado de una arquitectura recurrente híbrida (GRU–LSTM–GRU), diseñada para aprovechar la información temporal de las secuencias de video. Esta combinación permitió explorar el potencial de las redes recurrentes para refinar la coherencia métrica y mejorar la generalización del modelo ante personas de diferentes alturas y posiciones dentro de la escena.

En este sentido, el proyecto contribuye al avance del campo al proponer una solución ligera, accesible y orientada específicamente a usuarios y aplicaciones peatonales, proporcionando una alternativa viable frente a los modelos complejos y costosos actualmente dominantes.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{images/FDI1.pdf}
    \caption{Esquema de funcionamiento}
    \label{fig:blockDia}
\end{figure}

\subsection{Organización del proyecto técnico}
%El presente proyecto técnico se estructura en cuatro capítulos principales. En el Capítulo \ref{cap-intro}, se expone la introducción general al tema, incluyendo los antecedentes, la definición del problema, los objetivos, la justificación, la hipótesis, así como la aportación científica y tecnológica esperada.\\

El Capítulo \ref{cap-marcot} desarrolla el marco teórico, donde se describen los fundamentos conceptuales relacionados con la visión computacional, los enfoques monoculares, la estimación de profundidad y sus retos. \begin{comment}
    el movimiento desde la percepción de la cámara (ego-motion), la detección de objetos y el análisis de escenas dinámicas. Esta sección proporciona el contexto técnico y académico necesario para sustentar el desarrollo del proyecto.\\
\end{comment}
En el Capítulo \ref{cap-metodo}, se presenta el desarrollo completo y detallado de la metodología propuesta implementada.\begin{comment}
    el sistema de detección de objetos y estimación de distancias, desglosando cada una de las etapas del proceso, desde la recolección de datos hasta la validación del sistema en escenarios dinámicos.\\
\end{comment} 
Capitulo de resultados 
Finalmente, en el Capítulo \ref{cap-result} se incluirán las conclusiones obtenidas a partir del desarrollo del trabajo y la evaluación experimental, así como observaciones sobre posibles mejoras y aplicaciones futuras. El documento cierra con la sección de referencias que respalda el contenido técnico y científico del reporte.
